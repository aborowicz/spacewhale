/gpfs/projects/LynchGroup/spacewhale/git_spacewhale/spacewhale/shell_scripts
/gpfs/projects/LynchGroup/spacewhale
Wed Jun 19 12:00:15 EDT 2019
Now train resnet18 lr=0.0005
######################################################################################################
WELCOME TO SPACEWHALE!
######################################################################################################
We will now train your model.. please be patient
Using resnet18 Your trained model will be named resnet18_0005
------------------------------------------------------------------------------
<torch.utils.data.dataloader.DataLoader object at 0x2aaafcae97f0>
Your dataset size is: 12545
You have 2 classes in your dataset
------------------------------------------------------------------------------
Labels for the dataset are:
water = 0
whale = 1
------------------------------------------------------------------------------
Data loaded into gpu
------------------------------------------------------------------------------
Epoch 0/23
----------
train Loss: 0.5530 Acc: 0.7083 Err: 0.2917
TP: 4810.0000  TN: 4075.0000  FP: 2189.0000  FN: 1470.0000
Epoch 1/23
----------
train Loss: 0.4599 Acc: 0.7820 Err: 0.2179
TP: 5432.0000  TN: 4378.0000  FP: 1834.0000  FN: 900.0000
Epoch 2/23
----------
train Loss: 0.4197 Acc: 0.8107 Err: 0.1892
TP: 5719.0000  TN: 4451.0000  FP: 1727.0000  FN: 647.0000
Epoch 3/23
----------
train Loss: 0.4021 Acc: 0.8170 Err: 0.1829
TP: 5710.0000  TN: 4539.0000  FP: 1722.0000  FN: 573.0000
Epoch 4/23
----------
train Loss: 0.3922 Acc: 0.8251 Err: 0.1748
TP: 5740.0000  TN: 4611.0000  FP: 1665.0000  FN: 528.0000
Epoch 5/23
----------
train Loss: 0.3746 Acc: 0.8294 Err: 0.1705
TP: 5844.0000  TN: 4561.0000  FP: 1675.0000  FN: 464.0000
Epoch 6/23
----------
train Loss: 0.3627 Acc: 0.8390 Err: 0.1609
TP: 5852.0000  TN: 4673.0000  FP: 1610.0000  FN: 409.0000
Epoch 7/23
----------
train Loss: 0.3522 Acc: 0.8446 Err: 0.1553
TP: 5890.0000  TN: 4706.0000  FP: 1617.0000  FN: 331.0000
Epoch 8/23
----------
train Loss: 0.3421 Acc: 0.8486 Err: 0.1513
TP: 5997.0000  TN: 4649.0000  FP: 1576.0000  FN: 322.0000
Epoch 9/23
----------
train Loss: 0.3457 Acc: 0.8470 Err: 0.1530
TP: 6041.0000  TN: 4584.0000  FP: 1560.0000  FN: 359.0000
Epoch 10/23
----------
train Loss: 0.3380 Acc: 0.8524 Err: 0.1475
TP: 5928.0000  TN: 4765.0000  FP: 1514.0000  FN: 337.0000
Epoch 11/23
----------
train Loss: 0.3387 Acc: 0.8489 Err: 0.1511
TP: 5821.0000  TN: 4828.0000  FP: 1529.0000  FN: 366.0000
Epoch 12/23
----------
train Loss: 0.3331 Acc: 0.8546 Err: 0.1453
TP: 5981.0000  TN: 4740.0000  FP: 1502.0000  FN: 321.0000
Epoch 13/23
----------
train Loss: 0.3400 Acc: 0.8477 Err: 0.1522
TP: 5874.0000  TN: 4761.0000  FP: 1550.0000  FN: 359.0000
Epoch 14/23
----------
train Loss: 0.3385 Acc: 0.8538 Err: 0.1461
TP: 5961.0000  TN: 4750.0000  FP: 1482.0000  FN: 351.0000
Epoch 15/23
----------
train Loss: 0.3328 Acc: 0.8532 Err: 0.1468
TP: 5873.0000  TN: 4830.0000  FP: 1487.0000  FN: 354.0000
Epoch 16/23
----------
train Loss: 0.3217 Acc: 0.8594 Err: 0.1405
TP: 5946.0000  TN: 4835.0000  FP: 1438.0000  FN: 325.0000
Epoch 17/23
----------
train Loss: 0.3304 Acc: 0.8553 Err: 0.1446
TP: 6003.0000  TN: 4727.0000  FP: 1490.0000  FN: 324.0000
Epoch 18/23
----------
train Loss: 0.3327 Acc: 0.8529 Err: 0.1470
TP: 5887.0000  TN: 4813.0000  FP: 1519.0000  FN: 325.0000
Epoch 19/23
----------
train Loss: 0.3415 Acc: 0.8471 Err: 0.1528
TP: 5856.0000  TN: 4771.0000  FP: 1559.0000  FN: 358.0000
Epoch 20/23
----------
train Loss: 0.3345 Acc: 0.8489 Err: 0.1510
TP: 5915.0000  TN: 4735.0000  FP: 1535.0000  FN: 359.0000
Epoch 21/23
----------
train Loss: 0.3306 Acc: 0.8514 Err: 0.1485
TP: 5885.0000  TN: 4796.0000  FP: 1543.0000  FN: 320.0000
Epoch 22/23
----------
train Loss: 0.3420 Acc: 0.8503 Err: 0.1496
TP: 5936.0000  TN: 4731.0000  FP: 1527.0000  FN: 350.0000
Epoch 23/23
----------
train Loss: 0.3313 Acc: 0.8551 Err: 0.1448
TP: 5867.0000  TN: 4860.0000  FP: 1503.0000  FN: 314.0000
-----------------------------------------------------------
Training complete in 42m 55s
-----------------------------------------------------------
Wed Jun 19 12:43:28 EDT 2019
