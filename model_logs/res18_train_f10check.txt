/gpfs/projects/LynchGroup/spacewhale/git_spacewhale/spacewhale/shell_scripts
/gpfs/projects/LynchGroup/spacewhale
Wed Jun 26 13:13:41 EDT 2019
Now train resnet18 fold 10 checker
######################################################################################################
WELCOME TO SPACEWHALE!
######################################################################################################
We will now train your model.. please be patient
Using resnet18 Your trained model will be named resnet18_f10
------------------------------------------------------------------------------
<torch.utils.data.dataloader.DataLoader object at 0x2aaafcae97b8>
Your dataset size is: 11287
You have 2 classes in your dataset
------------------------------------------------------------------------------
Labels for the dataset are:
water = 0
whale = 1
------------------------------------------------------------------------------
Data loaded into gpu
------------------------------------------------------------------------------
Epoch 0/23
----------
train Loss: 0.5353 Acc: 0.7201 Err: 0.2778
TP: 4401.0000  TN: 3727.0000  FP: 1923.0000  FN: 1213.0000
Epoch 1/23
----------
train Loss: 0.4315 Acc: 0.7932 Err: 0.2047
TP: 4872.0000  TN: 4081.0000  FP: 1585.0000  FN: 726.0000
Epoch 2/23
----------
train Loss: 0.3916 Acc: 0.8225 Err: 0.1754
TP: 5106.0000  TN: 4178.0000  FP: 1431.0000  FN: 549.0000
Epoch 3/23
----------
train Loss: 0.3754 Acc: 0.8336 Err: 0.1643
TP: 5211.0000  TN: 4198.0000  FP: 1446.0000  FN: 409.0000
Epoch 4/23
----------
train Loss: 0.3666 Acc: 0.8386 Err: 0.1594
TP: 5325.0000  TN: 4140.0000  FP: 1411.0000  FN: 388.0000
Epoch 5/23
----------
train Loss: 0.3635 Acc: 0.8367 Err: 0.1612
TP: 5335.0000  TN: 4109.0000  FP: 1440.0000  FN: 380.0000
Epoch 6/23
----------
train Loss: 0.3478 Acc: 0.8467 Err: 0.1512
TP: 5386.0000  TN: 4171.0000  FP: 1406.0000  FN: 301.0000
Epoch 7/23
----------
train Loss: 0.3274 Acc: 0.8564 Err: 0.1416
TP: 5370.0000  TN: 4296.0000  FP: 1368.0000  FN: 230.0000
Epoch 8/23
----------
train Loss: 0.3224 Acc: 0.8557 Err: 0.1423
TP: 5401.0000  TN: 4257.0000  FP: 1351.0000  FN: 255.0000
Epoch 9/23
----------
train Loss: 0.3188 Acc: 0.8633 Err: 0.1347
TP: 5463.0000  TN: 4281.0000  FP: 1276.0000  FN: 244.0000
Epoch 10/23
----------
train Loss: 0.3194 Acc: 0.8582 Err: 0.1398
TP: 5394.0000  TN: 4292.0000  FP: 1320.0000  FN: 258.0000
Epoch 11/23
----------
train Loss: 0.3064 Acc: 0.8674 Err: 0.1306
TP: 5386.0000  TN: 4404.0000  FP: 1220.0000  FN: 254.0000
Epoch 12/23
----------
train Loss: 0.3188 Acc: 0.8617 Err: 0.1363
TP: 5456.0000  TN: 4270.0000  FP: 1272.0000  FN: 266.0000
Epoch 13/23
----------
train Loss: 0.3184 Acc: 0.8587 Err: 0.1393
TP: 5325.0000  TN: 4367.0000  FP: 1312.0000  FN: 260.0000
Epoch 14/23
----------
train Loss: 0.3129 Acc: 0.8590 Err: 0.1390
TP: 5323.0000  TN: 4372.0000  FP: 1325.0000  FN: 244.0000
Epoch 15/23
----------
train Loss: 0.3098 Acc: 0.8653 Err: 0.1326
TP: 5481.0000  TN: 4286.0000  FP: 1238.0000  FN: 259.0000
Epoch 16/23
----------
train Loss: 0.3166 Acc: 0.8590 Err: 0.1389
TP: 5338.0000  TN: 4358.0000  FP: 1311.0000  FN: 257.0000
Epoch 17/23
----------
train Loss: 0.3096 Acc: 0.8636 Err: 0.1344
TP: 5391.0000  TN: 4356.0000  FP: 1277.0000  FN: 240.0000
Epoch 18/23
----------
train Loss: 0.3046 Acc: 0.8636 Err: 0.1344
TP: 5251.0000  TN: 4496.0000  FP: 1277.0000  FN: 240.0000
Epoch 19/23
----------
train Loss: 0.3076 Acc: 0.8651 Err: 0.1329
TP: 5332.0000  TN: 4432.0000  FP: 1251.0000  FN: 249.0000
Epoch 20/23
----------
train Loss: 0.3076 Acc: 0.8639 Err: 0.1340
TP: 5427.0000  TN: 4324.0000  FP: 1275.0000  FN: 238.0000
Epoch 21/23
----------
train Loss: 0.3097 Acc: 0.8673 Err: 0.1307
TP: 5506.0000  TN: 4283.0000  FP: 1203.0000  FN: 272.0000
Epoch 22/23
----------
train Loss: 0.3082 Acc: 0.8678 Err: 0.1301
TP: 5228.0000  TN: 4567.0000  FP: 1260.0000  FN: 209.0000
Epoch 23/23
----------
train Loss: 0.3166 Acc: 0.8598 Err: 0.1381
TP: 5310.0000  TN: 4395.0000  FP: 1316.0000  FN: 243.0000
-----------------------------------------------------------
Training complete in 38m 49s
-----------------------------------------------------------
Wed Jun 26 13:52:53 EDT 2019
