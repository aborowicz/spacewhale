/gpfs/projects/LynchGroup/spacewhale/git_spacewhale/spacewhale/shell_scripts
/gpfs/projects/LynchGroup/spacewhale
Sat Jul  6 00:47:40 EDT 2019
######################################################################################################
WELCOME TO SPACEWHALE!
######################################################################################################
We will now train your model.. please be patient
Using resnet152 Your trained model will be named resnet152_full32_lr0007
------------------------------------------------------------------------------
<torch.utils.data.dataloader.DataLoader object at 0x2aaafcd13d30>
Your dataset size is: 12545
You have 2 classes in your dataset
------------------------------------------------------------------------------
Labels for the dataset are:
water = 0
whale = 1
------------------------------------------------------------------------------
Data loaded into gpu
------------------------------------------------------------------------------
Epoch 0/23
----------
train Loss: 0.4913 Acc: 0.7530 Err: 0.2469
TP: 5221.0000  TN: 4226.0000  FP: 2014.0000  FN: 1083.0000
Epoch 1/23
----------
train Loss: 0.3997 Acc: 0.8231 Err: 0.1768
TP: 5789.0000  TN: 4537.0000  FP: 1654.0000  FN: 564.0000
Epoch 2/23
----------
train Loss: 0.3669 Acc: 0.8382 Err: 0.1617
TP: 5888.0000  TN: 4627.0000  FP: 1603.0000  FN: 426.0000
Epoch 3/23
----------
train Loss: 0.3468 Acc: 0.8465 Err: 0.1534
TP: 5936.0000  TN: 4683.0000  FP: 1593.0000  FN: 332.0000
Epoch 4/23
----------
train Loss: 0.3365 Acc: 0.8544 Err: 0.1455
TP: 6005.0000  TN: 4714.0000  FP: 1480.0000  FN: 345.0000
Epoch 5/23
----------
train Loss: 0.3232 Acc: 0.8582 Err: 0.1417
TP: 5934.0000  TN: 4832.0000  FP: 1463.0000  FN: 315.0000
Epoch 6/23
----------
train Loss: 0.3220 Acc: 0.8599 Err: 0.1401
TP: 6042.0000  TN: 4745.0000  FP: 1477.0000  FN: 280.0000
Epoch 7/23
----------
train Loss: 0.3031 Acc: 0.8661 Err: 0.1338
TP: 6002.0000  TN: 4863.0000  FP: 1402.0000  FN: 277.0000
Epoch 8/23
----------
train Loss: 0.2996 Acc: 0.8704 Err: 0.1295
TP: 6043.0000  TN: 4876.0000  FP: 1354.0000  FN: 271.0000
Epoch 9/23
----------
train Loss: 0.2938 Acc: 0.8760 Err: 0.1239
TP: 6022.0000  TN: 4968.0000  FP: 1290.0000  FN: 264.0000
Epoch 10/23
----------
train Loss: 0.2996 Acc: 0.8697 Err: 0.1303
TP: 6043.0000  TN: 4867.0000  FP: 1366.0000  FN: 268.0000
Epoch 11/23
----------
train Loss: 0.2984 Acc: 0.8721 Err: 0.1279
TP: 5971.0000  TN: 4969.0000  FP: 1345.0000  FN: 259.0000
Epoch 12/23
----------
train Loss: 0.2999 Acc: 0.8677 Err: 0.1322
TP: 6047.0000  TN: 4838.0000  FP: 1382.0000  FN: 277.0000
Epoch 13/23
----------
train Loss: 0.2868 Acc: 0.8764 Err: 0.1236
TP: 6055.0000  TN: 4939.0000  FP: 1300.0000  FN: 250.0000
Epoch 14/23
----------
train Loss: 0.2957 Acc: 0.8744 Err: 0.1255
TP: 6064.0000  TN: 4905.0000  FP: 1340.0000  FN: 235.0000
Epoch 15/23
----------
train Loss: 0.2901 Acc: 0.8753 Err: 0.1246
TP: 6022.0000  TN: 4959.0000  FP: 1323.0000  FN: 240.0000
Epoch 16/23
----------
train Loss: 0.2909 Acc: 0.8743 Err: 0.1256
TP: 6108.0000  TN: 4860.0000  FP: 1321.0000  FN: 255.0000
Epoch 17/23
----------
train Loss: 0.2900 Acc: 0.8750 Err: 0.1249
TP: 6143.0000  TN: 4834.0000  FP: 1336.0000  FN: 231.0000
Epoch 18/23
----------
train Loss: 0.2958 Acc: 0.8741 Err: 0.1259
TP: 6021.0000  TN: 4944.0000  FP: 1309.0000  FN: 270.0000
Epoch 19/23
----------
train Loss: 0.2873 Acc: 0.8737 Err: 0.1262
TP: 5971.0000  TN: 4990.0000  FP: 1345.0000  FN: 238.0000
Epoch 20/23
----------
train Loss: 0.2898 Acc: 0.8753 Err: 0.1246
TP: 6019.0000  TN: 4962.0000  FP: 1318.0000  FN: 245.0000
Epoch 21/23
----------
train Loss: 0.2886 Acc: 0.8750 Err: 0.1249
TP: 6013.0000  TN: 4964.0000  FP: 1293.0000  FN: 274.0000
Epoch 22/23
----------
train Loss: 0.2935 Acc: 0.8745 Err: 0.1255
TP: 5886.0000  TN: 5084.0000  FP: 1326.0000  FN: 248.0000
Epoch 23/23
----------
train Loss: 0.2975 Acc: 0.8712 Err: 0.1287
TP: 5943.0000  TN: 4986.0000  FP: 1362.0000  FN: 253.0000
-----------------------------------------------------------
Training complete in 290m 31s
-----------------------------------------------------------
Sat Jul  6 05:38:57 EDT 2019
