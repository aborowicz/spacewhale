/gpfs/projects/LynchGroup/spacewhale/git_spacewhale/spacewhale/shell_scripts
/gpfs/projects/LynchGroup/spacewhale
Fri Jul  5 13:54:56 EDT 2019
######################################################################################################
WELCOME TO SPACEWHALE!
######################################################################################################
We will now train your model.. please be patient
Using resnet152 Your trained model will be named resnet152_full32_lr0009
------------------------------------------------------------------------------
<torch.utils.data.dataloader.DataLoader object at 0x2aaafcae97f0>
Your dataset size is: 12545
You have 2 classes in your dataset
------------------------------------------------------------------------------
Labels for the dataset are:
water = 0
whale = 1
------------------------------------------------------------------------------
Data loaded into gpu
------------------------------------------------------------------------------
Epoch 0/23
----------
train Loss: 0.4915 Acc: 0.7551 Err: 0.2448
TP: 5204.0000  TN: 4269.0000  FP: 1973.0000  FN: 1098.0000
Epoch 1/23
----------
train Loss: 0.3909 Acc: 0.8269 Err: 0.1731
TP: 5842.0000  TN: 4531.0000  FP: 1696.0000  FN: 475.0000
Epoch 2/23
----------
train Loss: 0.3618 Acc: 0.8420 Err: 0.1579
TP: 5915.0000  TN: 4648.0000  FP: 1599.0000  FN: 382.0000
Epoch 3/23
----------
train Loss: 0.3545 Acc: 0.8422 Err: 0.1577
TP: 5931.0000  TN: 4635.0000  FP: 1622.0000  FN: 356.0000
Epoch 4/23
----------
train Loss: 0.3435 Acc: 0.8475 Err: 0.1524
TP: 5914.0000  TN: 4718.0000  FP: 1589.0000  FN: 323.0000
Epoch 5/23
----------
train Loss: 0.3323 Acc: 0.8553 Err: 0.1446
TP: 6021.0000  TN: 4709.0000  FP: 1519.0000  FN: 295.0000
Epoch 6/23
----------
train Loss: 0.3292 Acc: 0.8545 Err: 0.1454
TP: 5928.0000  TN: 4792.0000  FP: 1497.0000  FN: 327.0000
Epoch 7/23
----------
train Loss: 0.3021 Acc: 0.8665 Err: 0.1334
TP: 5934.0000  TN: 4936.0000  FP: 1396.0000  FN: 278.0000
Epoch 8/23
----------
train Loss: 0.2939 Acc: 0.8745 Err: 0.1254
TP: 6053.0000  TN: 4918.0000  FP: 1317.0000  FN: 256.0000
Epoch 9/23
----------
train Loss: 0.2922 Acc: 0.8730 Err: 0.1269
TP: 6107.0000  TN: 4845.0000  FP: 1337.0000  FN: 255.0000
Epoch 10/23
----------
train Loss: 0.2946 Acc: 0.8752 Err: 0.1247
TP: 6081.0000  TN: 4899.0000  FP: 1298.0000  FN: 266.0000
Epoch 11/23
----------
train Loss: 0.3013 Acc: 0.8650 Err: 0.1350
TP: 5862.0000  TN: 4989.0000  FP: 1420.0000  FN: 273.0000
Epoch 12/23
----------
train Loss: 0.2875 Acc: 0.8744 Err: 0.1255
TP: 6056.0000  TN: 4913.0000  FP: 1314.0000  FN: 261.0000
Epoch 13/23
----------
train Loss: 0.2843 Acc: 0.8786 Err: 0.1213
TP: 6000.0000  TN: 5022.0000  FP: 1286.0000  FN: 236.0000
Epoch 14/23
----------
train Loss: 0.2897 Acc: 0.8702 Err: 0.1297
TP: 5931.0000  TN: 4986.0000  FP: 1344.0000  FN: 283.0000
Epoch 15/23
----------
train Loss: 0.2870 Acc: 0.8717 Err: 0.1283
TP: 5993.0000  TN: 4942.0000  FP: 1340.0000  FN: 269.0000
Epoch 16/23
----------
train Loss: 0.2903 Acc: 0.8721 Err: 0.1278
TP: 5998.0000  TN: 4943.0000  FP: 1335.0000  FN: 268.0000
Epoch 17/23
----------
train Loss: 0.2931 Acc: 0.8702 Err: 0.1297
TP: 5972.0000  TN: 4945.0000  FP: 1367.0000  FN: 260.0000
Epoch 18/23
----------
train Loss: 0.2908 Acc: 0.8727 Err: 0.1272
TP: 5944.0000  TN: 5004.0000  FP: 1326.0000  FN: 270.0000
Epoch 19/23
----------
train Loss: 0.2846 Acc: 0.8776 Err: 0.1223
TP: 5949.0000  TN: 5061.0000  FP: 1273.0000  FN: 261.0000
Epoch 20/23
----------
train Loss: 0.2855 Acc: 0.8779 Err: 0.1220
TP: 6034.0000  TN: 4979.0000  FP: 1298.0000  FN: 233.0000
Epoch 21/23
----------
train Loss: 0.2832 Acc: 0.8788 Err: 0.1212
TP: 5987.0000  TN: 5037.0000  FP: 1258.0000  FN: 262.0000
Epoch 22/23
----------
train Loss: 0.2903 Acc: 0.8736 Err: 0.1263
TP: 5999.0000  TN: 4960.0000  FP: 1311.0000  FN: 274.0000
Epoch 23/23
----------
train Loss: 0.2918 Acc: 0.8711 Err: 0.1288
TP: 6011.0000  TN: 4917.0000  FP: 1354.0000  FN: 262.0000
-----------------------------------------------------------
Training complete in 284m 1s
-----------------------------------------------------------
Fri Jul  5 18:39:19 EDT 2019
