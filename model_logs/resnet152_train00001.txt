/gpfs/projects/LynchGroup/spacewhale/git_spacewhale/spacewhale/shell_scripts
/gpfs/projects/LynchGroup/spacewhale
Tue Jul  9 15:56:32 EDT 2019
## NOW TRAINING RESNET-34, LR=0.00001
######################################################################################################
WELCOME TO SPACEWHALE!
######################################################################################################
We will now train your model.. please be patient
Using resnet152 Your trained model will be named resnet152_full32_lr00001
------------------------------------------------------------------------------
<torch.utils.data.dataloader.DataLoader object at 0x2aaafcd13f98>
Your dataset size is: 12545
You have 2 classes in your dataset
------------------------------------------------------------------------------
Labels for the dataset are:
water = 0
whale = 1
------------------------------------------------------------------------------
Data loaded into gpu
------------------------------------------------------------------------------
Epoch 0/23
----------
train Loss: 0.6879 Acc: 0.5468 Err: 0.4531
TP: 3347.0000  TN: 3513.0000  FP: 2853.0000  FN: 2831.0000
Epoch 1/23
----------
train Loss: 0.6546 Acc: 0.6187 Err: 0.3813
TP: 4103.0000  TN: 3658.0000  FP: 2600.0000  FN: 2183.0000
Epoch 2/23
----------
train Loss: 0.6326 Acc: 0.6548 Err: 0.3451
TP: 4366.0000  TN: 3849.0000  FP: 2457.0000  FN: 1872.0000
Epoch 3/23
----------
train Loss: 0.6138 Acc: 0.6859 Err: 0.3141
TP: 4976.0000  TN: 3628.0000  FP: 2529.0000  FN: 1411.0000
Epoch 4/23
----------
train Loss: 0.5916 Acc: 0.7088 Err: 0.2911
TP: 5041.0000  TN: 3851.0000  FP: 2381.0000  FN: 1271.0000
Epoch 5/23
----------
train Loss: 0.5769 Acc: 0.7134 Err: 0.2865
TP: 4957.0000  TN: 3993.0000  FP: 2338.0000  FN: 1256.0000
Epoch 6/23
----------
train Loss: 0.5653 Acc: 0.7232 Err: 0.2768
TP: 5078.0000  TN: 3994.0000  FP: 2317.0000  FN: 1155.0000
Epoch 7/23
----------
train Loss: 0.5550 Acc: 0.7313 Err: 0.2686
TP: 5192.0000  TN: 3982.0000  FP: 2216.0000  FN: 1154.0000
Epoch 8/23
----------
train Loss: 0.5539 Acc: 0.7354 Err: 0.2646
TP: 5223.0000  TN: 4002.0000  FP: 2265.0000  FN: 1054.0000
Epoch 9/23
----------
train Loss: 0.5545 Acc: 0.7354 Err: 0.2645
TP: 5280.0000  TN: 3946.0000  FP: 2250.0000  FN: 1068.0000
Epoch 10/23
----------
train Loss: 0.5543 Acc: 0.7322 Err: 0.2677
TP: 5264.0000  TN: 3922.0000  FP: 2315.0000  FN: 1043.0000
Epoch 11/23
----------
train Loss: 0.5520 Acc: 0.7379 Err: 0.2620
TP: 5265.0000  TN: 3992.0000  FP: 2294.0000  FN: 993.0000
Epoch 12/23
----------
train Loss: 0.5498 Acc: 0.7356 Err: 0.2643
TP: 5196.0000  TN: 4032.0000  FP: 2324.0000  FN: 992.0000
Epoch 13/23
----------
train Loss: 0.5453 Acc: 0.7384 Err: 0.2615
TP: 5240.0000  TN: 4023.0000  FP: 2201.0000  FN: 1080.0000
Epoch 14/23
----------
train Loss: 0.5501 Acc: 0.7296 Err: 0.2703
TP: 5209.0000  TN: 3944.0000  FP: 2296.0000  FN: 1095.0000
Epoch 15/23
----------
train Loss: 0.5403 Acc: 0.7438 Err: 0.2561
TP: 5284.0000  TN: 4047.0000  FP: 2227.0000  FN: 986.0000
Epoch 16/23
----------
train Loss: 0.5466 Acc: 0.7374 Err: 0.2625
TP: 5273.0000  TN: 3978.0000  FP: 2235.0000  FN: 1058.0000
Epoch 17/23
----------
train Loss: 0.5470 Acc: 0.7377 Err: 0.2623
TP: 5302.0000  TN: 3952.0000  FP: 2209.0000  FN: 1081.0000
Epoch 18/23
----------
train Loss: 0.5384 Acc: 0.7513 Err: 0.2486
TP: 5321.0000  TN: 4104.0000  FP: 2189.0000  FN: 930.0000
Epoch 19/23
----------
train Loss: 0.5457 Acc: 0.7393 Err: 0.2606
TP: 5272.0000  TN: 4003.0000  FP: 2231.0000  FN: 1038.0000
Epoch 20/23
----------
train Loss: 0.5472 Acc: 0.7384 Err: 0.2615
TP: 5242.0000  TN: 4021.0000  FP: 2247.0000  FN: 1034.0000
Epoch 21/23
----------
train Loss: 0.5503 Acc: 0.7375 Err: 0.2624
TP: 5301.0000  TN: 3951.0000  FP: 2263.0000  FN: 1029.0000
Epoch 22/23
----------
train Loss: 0.5427 Acc: 0.7411 Err: 0.2588
TP: 5260.0000  TN: 4037.0000  FP: 2243.0000  FN: 1004.0000
Epoch 23/23
----------
train Loss: 0.5491 Acc: 0.7402 Err: 0.2597
TP: 5276.0000  TN: 4010.0000  FP: 2256.0000  FN: 1002.0000
-----------------------------------------------------------
Training complete in 286m 20s
-----------------------------------------------------------
Tue Jul  9 20:43:18 EDT 2019
