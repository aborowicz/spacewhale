/gpfs/projects/LynchGroup/spacewhale/git_spacewhale/spacewhale/shell_scripts
/gpfs/projects/LynchGroup/spacewhale
Tue May  7 06:51:00 EDT 2019
######################################################################################################
WELCOME TO SPACEWHALE!
######################################################################################################
We will now train your model.. please be patient
Using resnet32 Your trained model will be named resnet32_full224_lr0009
------------------------------------------------------------------------------
<torch.utils.data.dataloader.DataLoader object at 0x2aaafcaea6d8>
Your dataset size is: 12545
You have 2 classes in your dataset
------------------------------------------------------------------------------
Labels for the dataset are:
water = 0
whale = 1
------------------------------------------------------------------------------
Data loaded into gpu
------------------------------------------------------------------------------
Epoch 0/23
----------
train Loss: 0.6767 Acc: 0.6526 Err: 0.3474
TP: 4572.0000  TN: 3615.0000  FP: 2660.0000  FN: 1698.0000
Epoch 1/23
----------
train Loss: 0.5299 Acc: 0.7469 Err: 0.2531
TP: 5438.0000  TN: 3932.0000  FP: 2305.0000  FN: 870.0000
Epoch 2/23
----------
train Loss: 0.4756 Acc: 0.7826 Err: 0.2174
TP: 5634.0000  TN: 4184.0000  FP: 2084.0000  FN: 643.0000
Epoch 3/23
----------
train Loss: 0.4589 Acc: 0.7928 Err: 0.2072
TP: 5801.0000  TN: 4145.0000  FP: 2025.0000  FN: 574.0000
Epoch 4/23
----------
train Loss: 0.4327 Acc: 0.8051 Err: 0.1949
TP: 5784.0000  TN: 4316.0000  FP: 1926.0000  FN: 519.0000
Epoch 5/23
----------
train Loss: 0.4208 Acc: 0.8133 Err: 0.1867
TP: 5788.0000  TN: 4415.0000  FP: 1857.0000  FN: 485.0000
Epoch 6/23
----------
train Loss: 0.4150 Acc: 0.8148 Err: 0.1852
TP: 5740.0000  TN: 4482.0000  FP: 1856.0000  FN: 467.0000
Epoch 7/23
----------
train Loss: 0.3729 Acc: 0.8379 Err: 0.1621
TP: 5894.0000  TN: 4617.0000  FP: 1651.0000  FN: 383.0000
Epoch 8/23
----------
train Loss: 0.3621 Acc: 0.8422 Err: 0.1578
TP: 5944.0000  TN: 4622.0000  FP: 1619.0000  FN: 360.0000
Epoch 9/23
----------
train Loss: 0.3524 Acc: 0.8459 Err: 0.1541
TP: 5986.0000  TN: 4626.0000  FP: 1596.0000  FN: 337.0000
Epoch 10/23
----------
train Loss: 0.3602 Acc: 0.8399 Err: 0.1601
TP: 5847.0000  TN: 4690.0000  FP: 1652.0000  FN: 356.0000
Epoch 11/23
----------
train Loss: 0.3542 Acc: 0.8496 Err: 0.1504
TP: 5982.0000  TN: 4676.0000  FP: 1579.0000  FN: 308.0000
Epoch 12/23
----------
train Loss: 0.3528 Acc: 0.8466 Err: 0.1534
TP: 5870.0000  TN: 4751.0000  FP: 1582.0000  FN: 342.0000
Epoch 13/23
----------
train Loss: 0.3414 Acc: 0.8532 Err: 0.1468
TP: 5941.0000  TN: 4762.0000  FP: 1510.0000  FN: 332.0000
Epoch 14/23
----------
train Loss: 0.3406 Acc: 0.8564 Err: 0.1436
TP: 6027.0000  TN: 4717.0000  FP: 1488.0000  FN: 313.0000
Epoch 15/23
----------
train Loss: 0.3395 Acc: 0.8534 Err: 0.1466
TP: 5887.0000  TN: 4819.0000  FP: 1526.0000  FN: 313.0000
Epoch 16/23
----------
train Loss: 0.3419 Acc: 0.8497 Err: 0.1503
TP: 5873.0000  TN: 4787.0000  FP: 1560.0000  FN: 325.0000
Epoch 17/23
----------
train Loss: 0.3403 Acc: 0.8517 Err: 0.1483
TP: 5970.0000  TN: 4715.0000  FP: 1503.0000  FN: 357.0000
Epoch 18/23
----------
train Loss: 0.3443 Acc: 0.8489 Err: 0.1511
TP: 5922.0000  TN: 4727.0000  FP: 1561.0000  FN: 335.0000
Epoch 19/23
----------
train Loss: 0.3431 Acc: 0.8527 Err: 0.1473
TP: 5834.0000  TN: 4863.0000  FP: 1525.0000  FN: 323.0000
Epoch 20/23
----------
train Loss: 0.3414 Acc: 0.8572 Err: 0.1428
TP: 5992.0000  TN: 4761.0000  FP: 1501.0000  FN: 291.0000
Epoch 21/23
----------
train Loss: 0.3398 Acc: 0.8529 Err: 0.1471
TP: 5945.0000  TN: 4755.0000  FP: 1544.0000  FN: 301.0000
Epoch 22/23
----------
train Loss: 0.3373 Acc: 0.8540 Err: 0.1460
TP: 5950.0000  TN: 4764.0000  FP: 1514.0000  FN: 317.0000
Epoch 23/23
----------
train Loss: 0.3362 Acc: 0.8545 Err: 0.1455
TP: 6005.0000  TN: 4715.0000  FP: 1498.0000  FN: 327.0000
-----------------------------------------------------------
Training complete in 124m 58s
-----------------------------------------------------------
Tue May  7 08:56:16 EDT 2019
