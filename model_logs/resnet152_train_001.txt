/gpfs/projects/LynchGroup/spacewhale/git_spacewhale/spacewhale/shell_scripts
/gpfs/projects/LynchGroup/spacewhale
Mon May 20 09:45:43 EDT 2019
######################################################################################################
WELCOME TO SPACEWHALE!
######################################################################################################
We will now train your model.. please be patient
Using resnet152 Your trained model will be named resnet152_001
------------------------------------------------------------------------------
<torch.utils.data.dataloader.DataLoader object at 0x2aaaaabed278>
Your dataset size is: 12545
You have 2 classes in your dataset
------------------------------------------------------------------------------
Labels for the dataset are:
water = 0
whale = 1
------------------------------------------------------------------------------
Data loaded into gpu
------------------------------------------------------------------------------
Epoch 0/23
----------
train Loss: 0.5672 Acc: 0.7147 Err: 0.2852
TP: 5021.0000  TN: 3945.0000  FP: 2297.0000  FN: 1281.0000
Epoch 1/23
----------
train Loss: 0.4566 Acc: 0.7890 Err: 0.2109
TP: 5629.0000  TN: 4269.0000  FP: 2003.0000  FN: 643.0000
Epoch 2/23
----------
train Loss: 0.4269 Acc: 0.8095 Err: 0.1904
TP: 5714.0000  TN: 4441.0000  FP: 1859.0000  FN: 530.0000
Epoch 3/23
----------
train Loss: 0.4091 Acc: 0.8168 Err: 0.1831
TP: 5787.0000  TN: 4460.0000  FP: 1818.0000  FN: 479.0000
Epoch 4/23
----------
train Loss: 0.3847 Acc: 0.8333 Err: 0.1666
TP: 5869.0000  TN: 4585.0000  FP: 1685.0000  FN: 405.0000
Epoch 5/23
----------
train Loss: 0.3801 Acc: 0.8335 Err: 0.1664
TP: 5845.0000  TN: 4611.0000  FP: 1697.0000  FN: 391.0000
Epoch 6/23
----------
train Loss: 0.3636 Acc: 0.8433 Err: 0.1566
TP: 5948.0000  TN: 4631.0000  FP: 1611.0000  FN: 354.0000
Epoch 7/23
----------
train Loss: 0.3547 Acc: 0.8434 Err: 0.1565
TP: 5926.0000  TN: 4655.0000  FP: 1617.0000  FN: 346.0000
Epoch 8/23
----------
train Loss: 0.3361 Acc: 0.8518 Err: 0.1481
TP: 5865.0000  TN: 4821.0000  FP: 1559.0000  FN: 299.0000
Epoch 9/23
----------
train Loss: 0.3217 Acc: 0.8633 Err: 0.1366
TP: 5982.0000  TN: 4848.0000  FP: 1429.0000  FN: 285.0000
Epoch 10/23
----------
train Loss: 0.3250 Acc: 0.8597 Err: 0.1402
TP: 6026.0000  TN: 4759.0000  FP: 1476.0000  FN: 283.0000
Epoch 11/23
----------
train Loss: 0.3203 Acc: 0.8609 Err: 0.1390
TP: 6030.0000  TN: 4770.0000  FP: 1472.0000  FN: 272.0000
Epoch 12/23
----------
train Loss: 0.3093 Acc: 0.8694 Err: 0.1306
TP: 6130.0000  TN: 4776.0000  FP: 1403.0000  FN: 235.0000
Epoch 13/23
----------
train Loss: 0.3249 Acc: 0.8577 Err: 0.1422
TP: 6005.0000  TN: 4755.0000  FP: 1485.0000  FN: 299.0000
Epoch 14/23
----------
train Loss: 0.3152 Acc: 0.8646 Err: 0.1353
TP: 6055.0000  TN: 4792.0000  FP: 1447.0000  FN: 250.0000
Epoch 15/23
----------
train Loss: 0.3216 Acc: 0.8585 Err: 0.1414
TP: 5966.0000  TN: 4804.0000  FP: 1512.0000  FN: 262.0000
Epoch 16/23
----------
train Loss: 0.3107 Acc: 0.8646 Err: 0.1353
TP: 6035.0000  TN: 4812.0000  FP: 1432.0000  FN: 265.0000
Epoch 17/23
----------
train Loss: 0.3039 Acc: 0.8673 Err: 0.1326
TP: 5989.0000  TN: 4891.0000  FP: 1419.0000  FN: 245.0000
Epoch 18/23
----------
train Loss: 0.3098 Acc: 0.8651 Err: 0.1348
TP: 6052.0000  TN: 4801.0000  FP: 1420.0000  FN: 271.0000
Epoch 19/23
----------
train Loss: 0.3072 Acc: 0.8704 Err: 0.1295
TP: 6035.0000  TN: 4884.0000  FP: 1379.0000  FN: 246.0000
Epoch 20/23
----------
train Loss: 0.3053 Acc: 0.8713 Err: 0.1286
TP: 6078.0000  TN: 4853.0000  FP: 1360.0000  FN: 253.0000
Epoch 21/23
----------
train Loss: 0.2998 Acc: 0.8709 Err: 0.1291
TP: 5974.0000  TN: 4951.0000  FP: 1385.0000  FN: 234.0000
Epoch 22/23
----------
train Loss: 0.3006 Acc: 0.8745 Err: 0.1255
TP: 6081.0000  TN: 4889.0000  FP: 1329.0000  FN: 245.0000
Epoch 23/23
----------
train Loss: 0.3077 Acc: 0.8670 Err: 0.1329
TP: 5988.0000  TN: 4889.0000  FP: 1405.0000  FN: 262.0000
-----------------------------------------------------------
Training complete in 417m 8s
-----------------------------------------------------------
Mon May 20 16:42:59 EDT 2019
