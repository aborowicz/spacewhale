/gpfs/projects/LynchGroup/spacewhale/git_spacewhale/spacewhale/shell_scripts
/gpfs/projects/LynchGroup/spacewhale
Sat Jul  6 05:39:09 EDT 2019
######################################################################################################
WELCOME TO SPACEWHALE!
######################################################################################################
We will now train your model.. please be patient
Using resnet152 Your trained model will be named resnet152_lr0005
------------------------------------------------------------------------------
<torch.utils.data.dataloader.DataLoader object at 0x2aaafcd0fa90>
Your dataset size is: 12545
You have 2 classes in your dataset
------------------------------------------------------------------------------
Labels for the dataset are:
water = 0
whale = 1
------------------------------------------------------------------------------
Data loaded into gpu
------------------------------------------------------------------------------
Epoch 0/23
----------
train Loss: 0.5172 Acc: 0.7424 Err: 0.2575
TP: 5079.0000  TN: 4235.0000  FP: 2012.0000  FN: 1218.0000
Epoch 1/23
----------
train Loss: 0.4079 Acc: 0.8155 Err: 0.1844
TP: 5559.0000  TN: 4672.0000  FP: 1663.0000  FN: 650.0000
Epoch 2/23
----------
train Loss: 0.3808 Acc: 0.8308 Err: 0.1692
TP: 5809.0000  TN: 4613.0000  FP: 1649.0000  FN: 473.0000
Epoch 3/23
----------
train Loss: 0.3560 Acc: 0.8400 Err: 0.1599
TP: 5848.0000  TN: 4690.0000  FP: 1586.0000  FN: 420.0000
Epoch 4/23
----------
train Loss: 0.3474 Acc: 0.8491 Err: 0.1508
TP: 5924.0000  TN: 4728.0000  FP: 1514.0000  FN: 378.0000
Epoch 5/23
----------
train Loss: 0.3335 Acc: 0.8498 Err: 0.1501
TP: 5900.0000  TN: 4761.0000  FP: 1529.0000  FN: 354.0000
Epoch 6/23
----------
train Loss: 0.3269 Acc: 0.8583 Err: 0.1416
TP: 5968.0000  TN: 4800.0000  FP: 1461.0000  FN: 315.0000
Epoch 7/23
----------
train Loss: 0.3176 Acc: 0.8606 Err: 0.1393
TP: 6013.0000  TN: 4783.0000  FP: 1491.0000  FN: 257.0000
Epoch 8/23
----------
train Loss: 0.3069 Acc: 0.8674 Err: 0.1325
TP: 6058.0000  TN: 4824.0000  FP: 1399.0000  FN: 263.0000
Epoch 9/23
----------
train Loss: 0.3068 Acc: 0.8666 Err: 0.1333
TP: 6108.0000  TN: 4764.0000  FP: 1421.0000  FN: 251.0000
Epoch 10/23
----------
train Loss: 0.3093 Acc: 0.8668 Err: 0.1331
TP: 5983.0000  TN: 4891.0000  FP: 1411.0000  FN: 259.0000
Epoch 11/23
----------
train Loss: 0.3063 Acc: 0.8667 Err: 0.1332
TP: 5997.0000  TN: 4876.0000  FP: 1373.0000  FN: 298.0000
Epoch 12/23
----------
train Loss: 0.3124 Acc: 0.8638 Err: 0.1361
TP: 6047.0000  TN: 4789.0000  FP: 1445.0000  FN: 263.0000
Epoch 13/23
----------
train Loss: 0.2945 Acc: 0.8706 Err: 0.1293
TP: 5994.0000  TN: 4928.0000  FP: 1357.0000  FN: 265.0000
Epoch 14/23
----------
train Loss: 0.2989 Acc: 0.8697 Err: 0.1303
TP: 5980.0000  TN: 4930.0000  FP: 1388.0000  FN: 246.0000
Epoch 15/23
----------
train Loss: 0.3000 Acc: 0.8699 Err: 0.1300
TP: 5963.0000  TN: 4950.0000  FP: 1370.0000  FN: 261.0000
Epoch 16/23
----------
train Loss: 0.2939 Acc: 0.8726 Err: 0.1273
TP: 6043.0000  TN: 4904.0000  FP: 1314.0000  FN: 283.0000
Epoch 17/23
----------
train Loss: 0.2961 Acc: 0.8731 Err: 0.1268
TP: 5926.0000  TN: 5027.0000  FP: 1315.0000  FN: 276.0000
Epoch 18/23
----------
train Loss: 0.3014 Acc: 0.8671 Err: 0.1328
TP: 6024.0000  TN: 4854.0000  FP: 1412.0000  FN: 254.0000
Epoch 19/23
----------
train Loss: 0.3015 Acc: 0.8679 Err: 0.1320
TP: 5956.0000  TN: 4932.0000  FP: 1368.0000  FN: 288.0000
Epoch 20/23
----------
train Loss: 0.3068 Acc: 0.8653 Err: 0.1346
TP: 5951.0000  TN: 4904.0000  FP: 1419.0000  FN: 270.0000
Epoch 21/23
----------
train Loss: 0.3098 Acc: 0.8670 Err: 0.1329
TP: 6021.0000  TN: 4856.0000  FP: 1382.0000  FN: 285.0000
Epoch 22/23
----------
train Loss: 0.2929 Acc: 0.8729 Err: 0.1271
TP: 6044.0000  TN: 4906.0000  FP: 1339.0000  FN: 255.0000
Epoch 23/23
----------
train Loss: 0.2916 Acc: 0.8741 Err: 0.1258
TP: 6056.0000  TN: 4910.0000  FP: 1320.0000  FN: 258.0000
-----------------------------------------------------------
Training complete in 290m 18s
-----------------------------------------------------------
Sat Jul  6 10:29:46 EDT 2019
