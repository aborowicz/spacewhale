/gpfs/projects/LynchGroup/spacewhale/git_spacewhale/spacewhale/shell_scripts
/gpfs/projects/LynchGroup/spacewhale
Fri Jul  5 14:02:05 EDT 2019
######################################################################################################
WELCOME TO SPACEWHALE!
######################################################################################################
We will now train your model.. please be patient
Using resnet152 Your trained model will be named resnet152_full32_lr0008
------------------------------------------------------------------------------
<torch.utils.data.dataloader.DataLoader object at 0x2aaafcae9908>
Your dataset size is: 12545
You have 2 classes in your dataset
------------------------------------------------------------------------------
Labels for the dataset are:
water = 0
whale = 1
------------------------------------------------------------------------------
Data loaded into gpu
------------------------------------------------------------------------------
Epoch 0/23
----------
train Loss: 0.4917 Acc: 0.7562 Err: 0.2438
TP: 5266.0000  TN: 4220.0000  FP: 2018.0000  FN: 1040.0000
Epoch 1/23
----------
train Loss: 0.3975 Acc: 0.8272 Err: 0.1727
TP: 5798.0000  TN: 4579.0000  FP: 1644.0000  FN: 523.0000
Epoch 2/23
----------
train Loss: 0.3639 Acc: 0.8393 Err: 0.1606
TP: 5857.0000  TN: 4672.0000  FP: 1601.0000  FN: 414.0000
Epoch 3/23
----------
train Loss: 0.3541 Acc: 0.8371 Err: 0.1628
TP: 5833.0000  TN: 4669.0000  FP: 1648.0000  FN: 394.0000
Epoch 4/23
----------
train Loss: 0.3381 Acc: 0.8504 Err: 0.1495
TP: 5858.0000  TN: 4810.0000  FP: 1510.0000  FN: 366.0000
Epoch 5/23
----------
train Loss: 0.3230 Acc: 0.8581 Err: 0.1418
TP: 5942.0000  TN: 4823.0000  FP: 1471.0000  FN: 308.0000
Epoch 6/23
----------
train Loss: 0.3217 Acc: 0.8591 Err: 0.1408
TP: 6059.0000  TN: 4719.0000  FP: 1467.0000  FN: 299.0000
Epoch 7/23
----------
train Loss: 0.3096 Acc: 0.8642 Err: 0.1357
TP: 5926.0000  TN: 4916.0000  FP: 1423.0000  FN: 279.0000
Epoch 8/23
----------
train Loss: 0.2971 Acc: 0.8674 Err: 0.1325
TP: 6011.0000  TN: 4871.0000  FP: 1389.0000  FN: 273.0000
Epoch 9/23
----------
train Loss: 0.2997 Acc: 0.8699 Err: 0.1300
TP: 6028.0000  TN: 4885.0000  FP: 1388.0000  FN: 243.0000
Epoch 10/23
----------
train Loss: 0.2894 Acc: 0.8728 Err: 0.1271
TP: 6033.0000  TN: 4916.0000  FP: 1354.0000  FN: 241.0000
Epoch 11/23
----------
train Loss: 0.2855 Acc: 0.8763 Err: 0.1236
TP: 6109.0000  TN: 4884.0000  FP: 1322.0000  FN: 229.0000
Epoch 12/23
----------
train Loss: 0.2912 Acc: 0.8720 Err: 0.1279
TP: 5980.0000  TN: 4959.0000  FP: 1343.0000  FN: 262.0000
Epoch 13/23
----------
train Loss: 0.2903 Acc: 0.8737 Err: 0.1263
TP: 6006.0000  TN: 4954.0000  FP: 1324.0000  FN: 260.0000
Epoch 14/23
----------
train Loss: 0.2870 Acc: 0.8741 Err: 0.1258
TP: 6072.0000  TN: 4894.0000  FP: 1368.0000  FN: 210.0000
Epoch 15/23
----------
train Loss: 0.2882 Acc: 0.8761 Err: 0.1238
TP: 6145.0000  TN: 4846.0000  FP: 1339.0000  FN: 214.0000
Epoch 16/23
----------
train Loss: 0.2848 Acc: 0.8770 Err: 0.1229
TP: 6018.0000  TN: 4984.0000  FP: 1334.0000  FN: 208.0000
Epoch 17/23
----------
train Loss: 0.2862 Acc: 0.8774 Err: 0.1225
TP: 5927.0000  TN: 5080.0000  FP: 1329.0000  FN: 208.0000
Epoch 18/23
----------
train Loss: 0.2904 Acc: 0.8709 Err: 0.1290
TP: 5973.0000  TN: 4953.0000  FP: 1367.0000  FN: 251.0000
Epoch 19/23
----------
train Loss: 0.2901 Acc: 0.8733 Err: 0.1267
TP: 6053.0000  TN: 4902.0000  FP: 1329.0000  FN: 260.0000
Epoch 20/23
----------
train Loss: 0.2881 Acc: 0.8753 Err: 0.1246
TP: 6018.0000  TN: 4963.0000  FP: 1291.0000  FN: 272.0000
Epoch 21/23
----------
train Loss: 0.2891 Acc: 0.8717 Err: 0.1282
TP: 5882.0000  TN: 5054.0000  FP: 1340.0000  FN: 268.0000
Epoch 22/23
----------
train Loss: 0.2867 Acc: 0.8780 Err: 0.1220
TP: 6168.0000  TN: 4846.0000  FP: 1284.0000  FN: 246.0000
Epoch 23/23
----------
train Loss: 0.2804 Acc: 0.8780 Err: 0.1219
TP: 6020.0000  TN: 4995.0000  FP: 1308.0000  FN: 221.0000
-----------------------------------------------------------
Training complete in 285m 53s
-----------------------------------------------------------
Fri Jul  5 18:48:20 EDT 2019
