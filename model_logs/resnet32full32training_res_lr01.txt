/gpfs/projects/LynchGroup/spacewhale/git_spacewhale/spacewhale/shell_scripts
/gpfs/projects/LynchGroup/spacewhale
Sun May  5 20:10:49 EDT 2019
######################################################################################################
WELCOME TO SPACEWHALE!
######################################################################################################
We will now train your model.. please be patient
Using resnet32 Your trained model will be named resnet32_full32_lr01
------------------------------------------------------------------------------
<torch.utils.data.dataloader.DataLoader object at 0x2aaafcaebb00>
Your dataset size is: 12545
You have 2 classes in your dataset
------------------------------------------------------------------------------
Labels for the dataset are:
water = 0
whale = 1
------------------------------------------------------------------------------
Data loaded into gpu
------------------------------------------------------------------------------
Epoch 0/23
----------
train Loss: 0.8568 Acc: 0.5283 Err: 0.4717
TP: 3380.0000  TN: 3247.0000  FP: 3134.0000  FN: 2784.0000
Epoch 1/23
----------
train Loss: 0.6648 Acc: 0.5680 Err: 0.4320
TP: 4488.0000  TN: 2637.0000  FP: 3723.0000  FN: 1697.0000
Epoch 2/23
----------
train Loss: 0.6489 Acc: 0.6065 Err: 0.3935
TP: 5368.0000  TN: 2240.0000  FP: 3977.0000  FN: 960.0000
Epoch 3/23
----------
train Loss: 0.6344 Acc: 0.6191 Err: 0.3809
TP: 5289.0000  TN: 2478.0000  FP: 3763.0000  FN: 1015.0000
Epoch 4/23
----------
train Loss: 0.6253 Acc: 0.6358 Err: 0.3642
TP: 5163.0000  TN: 2813.0000  FP: 3523.0000  FN: 1046.0000
Epoch 5/23
----------
train Loss: 0.6127 Acc: 0.6527 Err: 0.3473
TP: 5347.0000  TN: 2841.0000  FP: 3461.0000  FN: 896.0000
Epoch 6/23
----------
train Loss: 0.5969 Acc: 0.6749 Err: 0.3251
TP: 5586.0000  TN: 2880.0000  FP: 3298.0000  FN: 781.0000
Epoch 7/23
----------
train Loss: 0.5657 Acc: 0.7048 Err: 0.2952
TP: 5680.0000  TN: 3162.0000  FP: 3103.0000  FN: 600.0000
Epoch 8/23
----------
train Loss: 0.5594 Acc: 0.7073 Err: 0.2927
TP: 5637.0000  TN: 3236.0000  FP: 3016.0000  FN: 656.0000
Epoch 9/23
----------
train Loss: 0.5524 Acc: 0.7150 Err: 0.2850
TP: 5607.0000  TN: 3363.0000  FP: 2918.0000  FN: 657.0000
Epoch 10/23
----------
train Loss: 0.5366 Acc: 0.7324 Err: 0.2676
TP: 5673.0000  TN: 3515.0000  FP: 2720.0000  FN: 637.0000
Epoch 11/23
----------
train Loss: 0.5284 Acc: 0.7289 Err: 0.2711
TP: 5582.0000  TN: 3562.0000  FP: 2740.0000  FN: 661.0000
Epoch 12/23
----------
train Loss: 0.5304 Acc: 0.7362 Err: 0.2638
TP: 5655.0000  TN: 3581.0000  FP: 2661.0000  FN: 648.0000
Epoch 13/23
----------
train Loss: 0.5228 Acc: 0.7405 Err: 0.2595
TP: 5701.0000  TN: 3588.0000  FP: 2577.0000  FN: 679.0000
Epoch 14/23
----------
train Loss: 0.5228 Acc: 0.7424 Err: 0.2576
TP: 5669.0000  TN: 3645.0000  FP: 2587.0000  FN: 644.0000
Epoch 15/23
----------
train Loss: 0.5192 Acc: 0.7415 Err: 0.2585
TP: 5618.0000  TN: 3684.0000  FP: 2578.0000  FN: 665.0000
Epoch 16/23
----------
train Loss: 0.5181 Acc: 0.7473 Err: 0.2527
TP: 5678.0000  TN: 3697.0000  FP: 2536.0000  FN: 634.0000
Epoch 17/23
----------
train Loss: 0.5199 Acc: 0.7401 Err: 0.2599
TP: 5563.0000  TN: 3721.0000  FP: 2591.0000  FN: 670.0000
Epoch 18/23
----------
train Loss: 0.5030 Acc: 0.7554 Err: 0.2446
TP: 5573.0000  TN: 3904.0000  FP: 2452.0000  FN: 616.0000
Epoch 19/23
----------
train Loss: 0.5136 Acc: 0.7479 Err: 0.2521
TP: 5591.0000  TN: 3791.0000  FP: 2481.0000  FN: 682.0000
Epoch 20/23
----------
train Loss: 0.5094 Acc: 0.7520 Err: 0.2480
TP: 5570.0000  TN: 3864.0000  FP: 2447.0000  FN: 664.0000
Epoch 21/23
----------
train Loss: 0.5172 Acc: 0.7501 Err: 0.2499
TP: 5677.0000  TN: 3733.0000  FP: 2515.0000  FN: 620.0000
Epoch 22/23
----------
train Loss: 0.5075 Acc: 0.7514 Err: 0.2486
TP: 5557.0000  TN: 3869.0000  FP: 2475.0000  FN: 644.0000
Epoch 23/23
----------
train Loss: 0.5075 Acc: 0.7520 Err: 0.2480
TP: 5565.0000  TN: 3869.0000  FP: 2435.0000  FN: 676.0000
-----------------------------------------------------------
Training complete in 123m 42s
-----------------------------------------------------------
Sun May  5 22:14:40 EDT 2019
