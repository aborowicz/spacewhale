/gpfs/projects/LynchGroup/spacewhale/git_spacewhale/spacewhale/shell_scripts
/gpfs/projects/LynchGroup/spacewhale
Thu May  9 23:29:10 EDT 2019
######################################################################################################
WELCOME TO SPACEWHALE!
######################################################################################################
We will now train your model.. please be patient
Using resnet32 Your trained model will be named resnet32_full32_lr001
------------------------------------------------------------------------------
<torch.utils.data.dataloader.DataLoader object at 0x2aaaf73d6470>
Your dataset size is: 12545
You have 2 classes in your dataset
------------------------------------------------------------------------------
Labels for the dataset are:
water = 0
whale = 1
------------------------------------------------------------------------------
Data loaded into gpu
------------------------------------------------------------------------------
Epoch 0/23
----------
train Loss: 0.6819 Acc: 0.6543 Err: 0.3457
TP: 4593.0000  TN: 3615.0000  FP: 2643.0000  FN: 1694.0000
Epoch 1/23
----------
train Loss: 0.5254 Acc: 0.7482 Err: 0.2518
TP: 5484.0000  TN: 3902.0000  FP: 2341.0000  FN: 818.0000
Epoch 2/23
----------
train Loss: 0.4873 Acc: 0.7711 Err: 0.2289
TP: 5574.0000  TN: 4099.0000  FP: 2217.0000  FN: 655.0000
Epoch 3/23
----------
train Loss: 0.4608 Acc: 0.7945 Err: 0.2055
TP: 5648.0000  TN: 4319.0000  FP: 2021.0000  FN: 557.0000
Epoch 4/23
----------
train Loss: 0.4475 Acc: 0.7938 Err: 0.2062
TP: 5706.0000  TN: 4252.0000  FP: 2036.0000  FN: 551.0000
Epoch 5/23
----------
train Loss: 0.4259 Acc: 0.8112 Err: 0.1888
TP: 5857.0000  TN: 4319.0000  FP: 1868.0000  FN: 501.0000
Epoch 6/23
----------
train Loss: 0.4192 Acc: 0.8151 Err: 0.1849
TP: 5839.0000  TN: 4386.0000  FP: 1845.0000  FN: 475.0000
Epoch 7/23
----------
train Loss: 0.3776 Acc: 0.8338 Err: 0.1662
TP: 5901.0000  TN: 4559.0000  FP: 1695.0000  FN: 390.0000
Epoch 8/23
----------
train Loss: 0.3702 Acc: 0.8414 Err: 0.1586
TP: 5979.0000  TN: 4576.0000  FP: 1613.0000  FN: 377.0000
Epoch 9/23
----------
train Loss: 0.3693 Acc: 0.8392 Err: 0.1608
TP: 5937.0000  TN: 4591.0000  FP: 1637.0000  FN: 380.0000
Epoch 10/23
----------
train Loss: 0.3627 Acc: 0.8431 Err: 0.1569
TP: 5990.0000  TN: 4587.0000  FP: 1612.0000  FN: 356.0000
Epoch 11/23
----------
train Loss: 0.3638 Acc: 0.8420 Err: 0.1580
TP: 5900.0000  TN: 4663.0000  FP: 1641.0000  FN: 341.0000
Epoch 12/23
----------
train Loss: 0.3609 Acc: 0.8430 Err: 0.1570
TP: 6073.0000  TN: 4503.0000  FP: 1634.0000  FN: 335.0000
Epoch 13/23
----------
train Loss: 0.3503 Acc: 0.8482 Err: 0.1518
TP: 5956.0000  TN: 4685.0000  FP: 1563.0000  FN: 341.0000
Epoch 14/23
----------
train Loss: 0.3581 Acc: 0.8411 Err: 0.1589
TP: 5951.0000  TN: 4600.0000  FP: 1659.0000  FN: 335.0000
Epoch 15/23
----------
train Loss: 0.3542 Acc: 0.8446 Err: 0.1554
TP: 5958.0000  TN: 4637.0000  FP: 1613.0000  FN: 337.0000
Epoch 16/23
----------
train Loss: 0.3439 Acc: 0.8511 Err: 0.1489
TP: 5904.0000  TN: 4773.0000  FP: 1543.0000  FN: 325.0000
Epoch 17/23
----------
train Loss: 0.3617 Acc: 0.8438 Err: 0.1562
TP: 5963.0000  TN: 4622.0000  FP: 1603.0000  FN: 357.0000
Epoch 18/23
----------
train Loss: 0.3569 Acc: 0.8458 Err: 0.1542
TP: 5971.0000  TN: 4639.0000  FP: 1610.0000  FN: 325.0000
Epoch 19/23
----------
train Loss: 0.3528 Acc: 0.8454 Err: 0.1546
TP: 5880.0000  TN: 4726.0000  FP: 1595.0000  FN: 344.0000
Epoch 20/23
----------
train Loss: 0.3499 Acc: 0.8455 Err: 0.1545
TP: 5890.0000  TN: 4717.0000  FP: 1606.0000  FN: 332.0000
Epoch 21/23
----------
train Loss: 0.3473 Acc: 0.8519 Err: 0.1481
TP: 5932.0000  TN: 4755.0000  FP: 1534.0000  FN: 324.0000
Epoch 22/23
----------
train Loss: 0.3433 Acc: 0.8520 Err: 0.1480
TP: 5947.0000  TN: 4741.0000  FP: 1521.0000  FN: 336.0000
Epoch 23/23
----------
train Loss: 0.3520 Acc: 0.8474 Err: 0.1526
TP: 5963.0000  TN: 4668.0000  FP: 1558.0000  FN: 356.0000
-----------------------------------------------------------
Training complete in 126m 32s
-----------------------------------------------------------
Fri May 10 01:36:44 EDT 2019
