/gpfs/projects/LynchGroup/spacewhale/git_spacewhale/spacewhale/shell_scripts
/gpfs/projects/LynchGroup/spacewhale
Tue May  7 05:43:31 EDT 2019
######################################################################################################
WELCOME TO SPACEWHALE!
######################################################################################################
We will now train your model.. please be patient
Using resnet18 Your trained model will be named resnet18_full32_lr2
------------------------------------------------------------------------------
<torch.utils.data.dataloader.DataLoader object at 0x2aaafcaeab70>
Your dataset size is: 12545
You have 2 classes in your dataset
------------------------------------------------------------------------------
Labels for the dataset are:
water = 0
whale = 1
------------------------------------------------------------------------------
Data loaded into gpu
------------------------------------------------------------------------------
Epoch 0/23
----------
train Loss: 1.0836 Acc: 0.5005 Err: 0.4995
TP: 3284.0000  TN: 2995.0000  FP: 3229.0000  FN: 3037.0000
Epoch 1/23
----------
train Loss: 0.7563 Acc: 0.5098 Err: 0.4902
TP: 3222.0000  TN: 3173.0000  FP: 3102.0000  FN: 3048.0000
Epoch 2/23
----------
train Loss: 0.7410 Acc: 0.5322 Err: 0.4678
TP: 3491.0000  TN: 3185.0000  FP: 3068.0000  FN: 2801.0000
Epoch 3/23
----------
train Loss: 0.7219 Acc: 0.5408 Err: 0.4592
TP: 3513.0000  TN: 3271.0000  FP: 3063.0000  FN: 2698.0000
Epoch 4/23
----------
train Loss: 0.7231 Acc: 0.5474 Err: 0.4526
TP: 3749.0000  TN: 3118.0000  FP: 3133.0000  FN: 2545.0000
Epoch 5/23
----------
train Loss: 0.7297 Acc: 0.5456 Err: 0.4544
TP: 3763.0000  TN: 3082.0000  FP: 3171.0000  FN: 2529.0000
Epoch 6/23
----------
train Loss: 0.7155 Acc: 0.5567 Err: 0.4433
TP: 4054.0000  TN: 2930.0000  FP: 3152.0000  FN: 2409.0000
Epoch 7/23
----------
train Loss: 0.6528 Acc: 0.5861 Err: 0.4139
TP: 5145.0000  TN: 2208.0000  FP: 4012.0000  FN: 1180.0000
Epoch 8/23
----------
train Loss: 0.6525 Acc: 0.5867 Err: 0.4133
TP: 4928.0000  TN: 2432.0000  FP: 3876.0000  FN: 1309.0000
Epoch 9/23
----------
train Loss: 0.6486 Acc: 0.5974 Err: 0.4026
TP: 5300.0000  TN: 2194.0000  FP: 4048.0000  FN: 1003.0000
Epoch 10/23
----------
train Loss: 0.6459 Acc: 0.6011 Err: 0.3989
TP: 5226.0000  TN: 2315.0000  FP: 3912.0000  FN: 1092.0000
Epoch 11/23
----------
train Loss: 0.6502 Acc: 0.5978 Err: 0.4022
TP: 5011.0000  TN: 2488.0000  FP: 3809.0000  FN: 1237.0000
Epoch 12/23
----------
train Loss: 0.6419 Acc: 0.6144 Err: 0.3856
TP: 5323.0000  TN: 2385.0000  FP: 3873.0000  FN: 964.0000
Epoch 13/23
----------
train Loss: 0.6461 Acc: 0.6123 Err: 0.3877
TP: 5256.0000  TN: 2425.0000  FP: 3802.0000  FN: 1062.0000
Epoch 14/23
----------
train Loss: 0.6320 Acc: 0.6273 Err: 0.3727
TP: 5774.0000  TN: 2096.0000  FP: 4153.0000  FN: 522.0000
Epoch 15/23
----------
train Loss: 0.6264 Acc: 0.6430 Err: 0.3570
TP: 5939.0000  TN: 2128.0000  FP: 3993.0000  FN: 485.0000
Epoch 16/23
----------
train Loss: 0.6247 Acc: 0.6425 Err: 0.3575
TP: 5773.0000  TN: 2287.0000  FP: 3972.0000  FN: 513.0000
Epoch 17/23
----------
train Loss: 0.6262 Acc: 0.6418 Err: 0.3582
TP: 5780.0000  TN: 2271.0000  FP: 3959.0000  FN: 535.0000
Epoch 18/23
----------
train Loss: 0.6280 Acc: 0.6352 Err: 0.3648
TP: 5641.0000  TN: 2327.0000  FP: 3956.0000  FN: 621.0000
Epoch 19/23
----------
train Loss: 0.6281 Acc: 0.6386 Err: 0.3614
TP: 5693.0000  TN: 2318.0000  FP: 3907.0000  FN: 627.0000
Epoch 20/23
----------
train Loss: 0.6213 Acc: 0.6479 Err: 0.3521
TP: 5729.0000  TN: 2399.0000  FP: 3811.0000  FN: 606.0000
Epoch 21/23
----------
train Loss: 0.6239 Acc: 0.6440 Err: 0.3560
TP: 5656.0000  TN: 2423.0000  FP: 3873.0000  FN: 593.0000
Epoch 22/23
----------
train Loss: 0.6215 Acc: 0.6495 Err: 0.3505
TP: 5774.0000  TN: 2374.0000  FP: 3811.0000  FN: 586.0000
Epoch 23/23
----------
train Loss: 0.6180 Acc: 0.6526 Err: 0.3474
TP: 5840.0000  TN: 2347.0000  FP: 3811.0000  FN: 547.0000
-----------------------------------------------------------
Training complete in 67m 1s
-----------------------------------------------------------
Tue May  7 06:50:56 EDT 2019
