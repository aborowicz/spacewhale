/gpfs/projects/LynchGroup/spacewhale/git_spacewhale/spacewhale/shell_scripts
/gpfs/projects/LynchGroup/spacewhale
Sat Jul  6 00:48:31 EDT 2019
######################################################################################################
WELCOME TO SPACEWHALE!
######################################################################################################
We will now train your model.. please be patient
Using resnet152 Your trained model will be named resnet152_full32_lr0006
------------------------------------------------------------------------------
<torch.utils.data.dataloader.DataLoader object at 0x2aaafcd13be0>
Your dataset size is: 12545
You have 2 classes in your dataset
------------------------------------------------------------------------------
Labels for the dataset are:
water = 0
whale = 1
------------------------------------------------------------------------------
Data loaded into gpu
------------------------------------------------------------------------------
Epoch 0/23
----------
train Loss: 0.4947 Acc: 0.7570 Err: 0.2430
TP: 5120.0000  TN: 4376.0000  FP: 1967.0000  FN: 1081.0000
Epoch 1/23
----------
train Loss: 0.3953 Acc: 0.8246 Err: 0.1753
TP: 5762.0000  TN: 4583.0000  FP: 1653.0000  FN: 546.0000
Epoch 2/23
----------
train Loss: 0.3578 Acc: 0.8430 Err: 0.1569
TP: 5756.0000  TN: 4820.0000  FP: 1536.0000  FN: 432.0000
Epoch 3/23
----------
train Loss: 0.3461 Acc: 0.8462 Err: 0.1537
TP: 5822.0000  TN: 4794.0000  FP: 1528.0000  FN: 400.0000
Epoch 4/23
----------
train Loss: 0.3376 Acc: 0.8539 Err: 0.1460
TP: 5971.0000  TN: 4741.0000  FP: 1487.0000  FN: 345.0000
Epoch 5/23
----------
train Loss: 0.3394 Acc: 0.8544 Err: 0.1456
TP: 5981.0000  TN: 4737.0000  FP: 1496.0000  FN: 330.0000
Epoch 6/23
----------
train Loss: 0.3234 Acc: 0.8597 Err: 0.1402
TP: 6091.0000  TN: 4694.0000  FP: 1469.0000  FN: 290.0000
Epoch 7/23
----------
train Loss: 0.3122 Acc: 0.8631 Err: 0.1369
TP: 6068.0000  TN: 4759.0000  FP: 1498.0000  FN: 219.0000
Epoch 8/23
----------
train Loss: 0.3175 Acc: 0.8614 Err: 0.1385
TP: 5994.0000  TN: 4812.0000  FP: 1462.0000  FN: 276.0000
Epoch 9/23
----------
train Loss: 0.3089 Acc: 0.8661 Err: 0.1338
TP: 5986.0000  TN: 4879.0000  FP: 1414.0000  FN: 265.0000
Epoch 10/23
----------
train Loss: 0.3041 Acc: 0.8680 Err: 0.1319
TP: 6010.0000  TN: 4879.0000  FP: 1388.0000  FN: 267.0000
Epoch 11/23
----------
train Loss: 0.2977 Acc: 0.8729 Err: 0.1270
TP: 6097.0000  TN: 4854.0000  FP: 1336.0000  FN: 257.0000
Epoch 12/23
----------
train Loss: 0.2911 Acc: 0.8753 Err: 0.1246
TP: 6019.0000  TN: 4962.0000  FP: 1332.0000  FN: 231.0000
Epoch 13/23
----------
train Loss: 0.2964 Acc: 0.8723 Err: 0.1276
TP: 5946.0000  TN: 4997.0000  FP: 1357.0000  FN: 244.0000
Epoch 14/23
----------
train Loss: 0.2946 Acc: 0.8697 Err: 0.1302
TP: 6012.0000  TN: 4899.0000  FP: 1351.0000  FN: 282.0000
Epoch 15/23
----------
train Loss: 0.2956 Acc: 0.8733 Err: 0.1266
TP: 5995.0000  TN: 4961.0000  FP: 1339.0000  FN: 249.0000
Epoch 16/23
----------
train Loss: 0.2924 Acc: 0.8720 Err: 0.1279
TP: 6092.0000  TN: 4847.0000  FP: 1354.0000  FN: 251.0000
Epoch 17/23
----------
train Loss: 0.2945 Acc: 0.8702 Err: 0.1297
TP: 5993.0000  TN: 4924.0000  FP: 1369.0000  FN: 258.0000
Epoch 18/23
----------
train Loss: 0.2886 Acc: 0.8747 Err: 0.1252
TP: 6051.0000  TN: 4922.0000  FP: 1303.0000  FN: 268.0000
Epoch 19/23
----------
train Loss: 0.2981 Acc: 0.8679 Err: 0.1320
TP: 6046.0000  TN: 4842.0000  FP: 1395.0000  FN: 261.0000
Epoch 20/23
----------
train Loss: 0.2871 Acc: 0.8768 Err: 0.1231
TP: 6092.0000  TN: 4908.0000  FP: 1314.0000  FN: 230.0000
Epoch 21/23
----------
train Loss: 0.2956 Acc: 0.8705 Err: 0.1294
TP: 6010.0000  TN: 4911.0000  FP: 1378.0000  FN: 245.0000
Epoch 22/23
----------
train Loss: 0.2952 Acc: 0.8697 Err: 0.1302
TP: 5926.0000  TN: 4985.0000  FP: 1371.0000  FN: 262.0000
Epoch 23/23
----------
train Loss: 0.2907 Acc: 0.8726 Err: 0.1273
TP: 6029.0000  TN: 4918.0000  FP: 1345.0000  FN: 252.0000
-----------------------------------------------------------
Training complete in 291m 41s
-----------------------------------------------------------
Sat Jul  6 05:41:03 EDT 2019
