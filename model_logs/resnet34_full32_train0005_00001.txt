/gpfs/projects/LynchGroup/spacewhale/git_spacewhale/spacewhale/shell_scripts
/gpfs/projects/LynchGroup/spacewhale
Sun Jul  7 22:04:17 EDT 2019
NOW Training ResNet-34, LR= 0.0005
######################################################################################################
WELCOME TO SPACEWHALE!
######################################################################################################
We will now train your model.. please be patient
Using resnet32 Your trained model will be named resnet34_full32_lr0005
------------------------------------------------------------------------------
<torch.utils.data.dataloader.DataLoader object at 0x2aaafcbeab00>
Your dataset size is: 12545
You have 2 classes in your dataset
------------------------------------------------------------------------------
Labels for the dataset are:
water = 0
whale = 1
------------------------------------------------------------------------------
Data loaded into gpu
------------------------------------------------------------------------------
Epoch 0/23
----------
train Loss: 0.5576 Acc: 0.7058 Err: 0.2941
TP: 4857.0000  TN: 3997.0000  FP: 2263.0000  FN: 1427.0000
Epoch 1/23
----------
train Loss: 0.4503 Acc: 0.7881 Err: 0.2118
TP: 5489.0000  TN: 4398.0000  FP: 1904.0000  FN: 753.0000
Epoch 2/23
----------
train Loss: 0.4029 Acc: 0.8179 Err: 0.1821
TP: 5698.0000  TN: 4562.0000  FP: 1734.0000  FN: 550.0000
Epoch 3/23
----------
train Loss: 0.3862 Acc: 0.8271 Err: 0.1728
TP: 5780.0000  TN: 4596.0000  FP: 1665.0000  FN: 503.0000
Epoch 4/23
----------
train Loss: 0.3799 Acc: 0.8309 Err: 0.1690
TP: 5807.0000  TN: 4617.0000  FP: 1650.0000  FN: 470.0000
Epoch 5/23
----------
train Loss: 0.3629 Acc: 0.8364 Err: 0.1635
TP: 5807.0000  TN: 4686.0000  FP: 1618.0000  FN: 433.0000
Epoch 6/23
----------
train Loss: 0.3568 Acc: 0.8437 Err: 0.1562
TP: 5891.0000  TN: 4693.0000  FP: 1597.0000  FN: 363.0000
Epoch 7/23
----------
train Loss: 0.3467 Acc: 0.8458 Err: 0.1541
TP: 5865.0000  TN: 4746.0000  FP: 1588.0000  FN: 345.0000
Epoch 8/23
----------
train Loss: 0.3245 Acc: 0.8570 Err: 0.1429
TP: 5996.0000  TN: 4755.0000  FP: 1494.0000  FN: 299.0000
Epoch 9/23
----------
train Loss: 0.3320 Acc: 0.8519 Err: 0.1480
TP: 6033.0000  TN: 4654.0000  FP: 1532.0000  FN: 325.0000
Epoch 10/23
----------
train Loss: 0.3222 Acc: 0.8612 Err: 0.1387
TP: 5988.0000  TN: 4816.0000  FP: 1467.0000  FN: 273.0000
Epoch 11/23
----------
train Loss: 0.3333 Acc: 0.8510 Err: 0.1489
TP: 5909.0000  TN: 4767.0000  FP: 1537.0000  FN: 331.0000
Epoch 12/23
----------
train Loss: 0.3281 Acc: 0.8563 Err: 0.1436
TP: 5952.0000  TN: 4790.0000  FP: 1516.0000  FN: 286.0000
Epoch 13/23
----------
train Loss: 0.3283 Acc: 0.8532 Err: 0.1467
TP: 5953.0000  TN: 4751.0000  FP: 1523.0000  FN: 317.0000
Epoch 14/23
----------
train Loss: 0.3148 Acc: 0.8639 Err: 0.1360
TP: 6012.0000  TN: 4826.0000  FP: 1451.0000  FN: 255.0000
Epoch 15/23
----------
train Loss: 0.3180 Acc: 0.8608 Err: 0.1391
TP: 5948.0000  TN: 4851.0000  FP: 1473.0000  FN: 272.0000
Epoch 16/23
----------
train Loss: 0.3183 Acc: 0.8594 Err: 0.1405
TP: 5962.0000  TN: 4819.0000  FP: 1478.0000  FN: 285.0000
Epoch 17/23
----------
train Loss: 0.3088 Acc: 0.8652 Err: 0.1347
TP: 6062.0000  TN: 4792.0000  FP: 1420.0000  FN: 270.0000
Epoch 18/23
----------
train Loss: 0.3165 Acc: 0.8610 Err: 0.1389
TP: 5931.0000  TN: 4870.0000  FP: 1451.0000  FN: 292.0000
Epoch 19/23
----------
train Loss: 0.3130 Acc: 0.8620 Err: 0.1379
TP: 6037.0000  TN: 4777.0000  FP: 1454.0000  FN: 276.0000
Epoch 20/23
----------
train Loss: 0.3148 Acc: 0.8632 Err: 0.1367
TP: 6037.0000  TN: 4792.0000  FP: 1431.0000  FN: 284.0000
Epoch 21/23
----------
train Loss: 0.3200 Acc: 0.8623 Err: 0.1377
TP: 6092.0000  TN: 4725.0000  FP: 1445.0000  FN: 282.0000
Epoch 22/23
----------
train Loss: 0.3193 Acc: 0.8612 Err: 0.1387
TP: 6036.0000  TN: 4768.0000  FP: 1453.0000  FN: 287.0000
Epoch 23/23
----------
train Loss: 0.3156 Acc: 0.8622 Err: 0.1377
TP: 5972.0000  TN: 4844.0000  FP: 1458.0000  FN: 270.0000
-----------------------------------------------------------
Training complete in 76m 42s
-----------------------------------------------------------
Sun Jul  7 23:21:20 EDT 2019
NOW Training ResNet-34, LR= 0.00001
######################################################################################################
WELCOME TO SPACEWHALE!
######################################################################################################
We will now train your model.. please be patient
Using resnet32 Your trained model will be named resnet34_full32_lr00001
------------------------------------------------------------------------------
<torch.utils.data.dataloader.DataLoader object at 0x2aaafcd13be0>
Your dataset size is: 12545
You have 2 classes in your dataset
------------------------------------------------------------------------------
Labels for the dataset are:
water = 0
whale = 1
------------------------------------------------------------------------------
Data loaded into gpu
------------------------------------------------------------------------------
Epoch 0/23
----------
train Loss: 0.5729 Acc: 0.6942 Err: 0.3057
TP: 4700.0000  TN: 4009.0000  FP: 2313.0000  FN: 1522.0000
Epoch 1/23
----------
train Loss: 0.4505 Acc: 0.7881 Err: 0.2118
TP: 5500.0000  TN: 4387.0000  FP: 1913.0000  FN: 744.0000
Epoch 2/23
----------
train Loss: 0.4226 Acc: 0.8027 Err: 0.1972
TP: 5681.0000  TN: 4389.0000  FP: 1833.0000  FN: 641.0000
Epoch 3/23
----------
train Loss: 0.3881 Acc: 0.8261 Err: 0.1738
TP: 5839.0000  TN: 4525.0000  FP: 1700.0000  FN: 480.0000
Epoch 4/23
----------
train Loss: 0.3747 Acc: 0.8346 Err: 0.1653
TP: 5898.0000  TN: 4572.0000  FP: 1651.0000  FN: 423.0000
Epoch 5/23
----------
train Loss: 0.3707 Acc: 0.8327 Err: 0.1672
TP: 5860.0000  TN: 4586.0000  FP: 1661.0000  FN: 437.0000
Epoch 6/23
----------
train Loss: 0.3611 Acc: 0.8411 Err: 0.1589
TP: 5883.0000  TN: 4668.0000  FP: 1611.0000  FN: 382.0000
Epoch 7/23
----------
train Loss: 0.3575 Acc: 0.8418 Err: 0.1582
TP: 5991.0000  TN: 4569.0000  FP: 1651.0000  FN: 333.0000
Epoch 8/23
----------
train Loss: 0.3331 Acc: 0.8543 Err: 0.1456
TP: 6052.0000  TN: 4665.0000  FP: 1538.0000  FN: 289.0000
Epoch 9/23
----------
train Loss: 0.3403 Acc: 0.8498 Err: 0.1501
TP: 5971.0000  TN: 4690.0000  FP: 1581.0000  FN: 302.0000
Epoch 10/23
----------
train Loss: 0.3355 Acc: 0.8540 Err: 0.1459
TP: 6028.0000  TN: 4686.0000  FP: 1526.0000  FN: 304.0000
Epoch 11/23
----------
train Loss: 0.3275 Acc: 0.8564 Err: 0.1435
TP: 5929.0000  TN: 4815.0000  FP: 1510.0000  FN: 290.0000
Epoch 12/23
----------
train Loss: 0.3231 Acc: 0.8582 Err: 0.1417
TP: 5974.0000  TN: 4792.0000  FP: 1499.0000  FN: 279.0000
Epoch 13/23
----------
train Loss: 0.3246 Acc: 0.8564 Err: 0.1435
TP: 5918.0000  TN: 4826.0000  FP: 1496.0000  FN: 304.0000
Epoch 14/23
----------
train Loss: 0.3232 Acc: 0.8582 Err: 0.1417
TP: 6027.0000  TN: 4739.0000  FP: 1473.0000  FN: 305.0000
Epoch 15/23
----------
train Loss: 0.3286 Acc: 0.8548 Err: 0.1451
TP: 5948.0000  TN: 4776.0000  FP: 1515.0000  FN: 305.0000
Epoch 16/23
----------
train Loss: 0.3343 Acc: 0.8540 Err: 0.1460
TP: 5930.0000  TN: 4783.0000  FP: 1529.0000  FN: 302.0000
Epoch 17/23
----------
train Loss: 0.3206 Acc: 0.8600 Err: 0.1399
TP: 6011.0000  TN: 4778.0000  FP: 1485.0000  FN: 270.0000
Epoch 18/23
----------
train Loss: 0.3223 Acc: 0.8590 Err: 0.1409
TP: 5955.0000  TN: 4821.0000  FP: 1489.0000  FN: 279.0000
Epoch 19/23
----------
train Loss: 0.3243 Acc: 0.8588 Err: 0.1411
TP: 6039.0000  TN: 4735.0000  FP: 1471.0000  FN: 299.0000
Epoch 20/23
----------
train Loss: 0.3170 Acc: 0.8611 Err: 0.1388
TP: 5965.0000  TN: 4838.0000  FP: 1471.0000  FN: 270.0000
Epoch 21/23
----------
train Loss: 0.3293 Acc: 0.8551 Err: 0.1448
TP: 6029.0000  TN: 4698.0000  FP: 1517.0000  FN: 300.0000
Epoch 22/23
----------
train Loss: 0.3173 Acc: 0.8597 Err: 0.1402
TP: 5996.0000  TN: 4789.0000  FP: 1465.0000  FN: 294.0000
Epoch 23/23
----------
train Loss: 0.3206 Acc: 0.8604 Err: 0.1395
TP: 5940.0000  TN: 4854.0000  FP: 1460.0000  FN: 290.0000
-----------------------------------------------------------
Training complete in 76m 40s
-----------------------------------------------------------
Mon Jul  8 00:38:16 EDT 2019
